{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1bcfd1e8e3f74c3986a8835aa3e60272": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ac197af39d454bdab5a95cde348d7779",
       "IPY_MODEL_736b1ad636c04ef5a81f9c847d4e07d0",
       "IPY_MODEL_395e978a53ca4a889114e354bb381cee"
      ],
      "layout": "IPY_MODEL_a30e9ec94fe944e2ba372056fd82c1d3"
     }
    },
    "ac197af39d454bdab5a95cde348d7779": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_752d04cc19c340e7bb12a089dcfb849c",
      "placeholder": "​",
      "style": "IPY_MODEL_a5ff8ec368d24ec2baf63382ee60c5e7",
      "value": "README.md: 100%"
     }
    },
    "736b1ad636c04ef5a81f9c847d4e07d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ea1968fdea945299cfb6f7b5580b9e8",
      "max": 262,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_610cf0065176473bbf5246a42103d0d6",
      "value": 262
     }
    },
    "395e978a53ca4a889114e354bb381cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_084704771f724cbabbc603bfb611ab23",
      "placeholder": "​",
      "style": "IPY_MODEL_5b3627a955be4eafb85f6071cf1d9d17",
      "value": " 262/262 [00:00&lt;00:00, 16.6kB/s]"
     }
    },
    "a30e9ec94fe944e2ba372056fd82c1d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "752d04cc19c340e7bb12a089dcfb849c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5ff8ec368d24ec2baf63382ee60c5e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4ea1968fdea945299cfb6f7b5580b9e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "610cf0065176473bbf5246a42103d0d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "084704771f724cbabbc603bfb611ab23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b3627a955be4eafb85f6071cf1d9d17": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab5dd08012484710a9ac2da6fb377268": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f3bbb58549e4cbba225e256760c2632",
       "IPY_MODEL_bad60489dfb144858d78bf4d54e83ba5",
       "IPY_MODEL_9e78e4699b0240bdb5d05532215fe23d"
      ],
      "layout": "IPY_MODEL_561fdfe427e2447ab3cfbd3c3fa85bcb"
     }
    },
    "6f3bbb58549e4cbba225e256760c2632": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ca58cc8ff04474299fd139f85e38e45",
      "placeholder": "​",
      "style": "IPY_MODEL_cf04f6aecf474c6387283322a6136d31",
      "value": "(…)-00000-of-00001-f131735b1a05d489.parquet: 100%"
     }
    },
    "bad60489dfb144858d78bf4d54e83ba5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c95494b0d0ed42f4b009b9a5778fe9a3",
      "max": 2066798,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1efa899219214297911274a303cd7389",
      "value": 2066798
     }
    },
    "9e78e4699b0240bdb5d05532215fe23d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c0bd7cfb3b44d288398a8f73f6a19e3",
      "placeholder": "​",
      "style": "IPY_MODEL_7903b5394108418e8f8c66821073ad80",
      "value": " 2.07M/2.07M [00:00&lt;00:00, 10.5MB/s]"
     }
    },
    "561fdfe427e2447ab3cfbd3c3fa85bcb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ca58cc8ff04474299fd139f85e38e45": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf04f6aecf474c6387283322a6136d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c95494b0d0ed42f4b009b9a5778fe9a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1efa899219214297911274a303cd7389": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c0bd7cfb3b44d288398a8f73f6a19e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7903b5394108418e8f8c66821073ad80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5871cdfae919416da2837b2c746efcdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51a511d66ff6429fbdd4f27622358f13",
       "IPY_MODEL_c3bcd2901f3a4699a4e8f1003bec25e8",
       "IPY_MODEL_0f2f0cc6c9b54e81b8b7985edb6342fd"
      ],
      "layout": "IPY_MODEL_6cac8841688a4a8fa9e0f5a7795c03ce"
     }
    },
    "51a511d66ff6429fbdd4f27622358f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6232b9fcbb22494ab60df30ef75a81d8",
      "placeholder": "​",
      "style": "IPY_MODEL_9ed4bbc6435f458d8a53d375b69d8063",
      "value": "Generating train split: 100%"
     }
    },
    "c3bcd2901f3a4699a4e8f1003bec25e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_696b177d73314e45bfbe90819c9de6cb",
      "max": 2322,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24b24dbf87db4d8db04b6ce134563478",
      "value": 2322
     }
    },
    "0f2f0cc6c9b54e81b8b7985edb6342fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddd08cc88c474ac79a9a8f2d066f6544",
      "placeholder": "​",
      "style": "IPY_MODEL_cfe9983cd9b84138b2ca8e8c05c71c49",
      "value": " 2322/2322 [00:00&lt;00:00, 23834.48 examples/s]"
     }
    },
    "6cac8841688a4a8fa9e0f5a7795c03ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6232b9fcbb22494ab60df30ef75a81d8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed4bbc6435f458d8a53d375b69d8063": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "696b177d73314e45bfbe90819c9de6cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24b24dbf87db4d8db04b6ce134563478": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ddd08cc88c474ac79a9a8f2d066f6544": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfe9983cd9b84138b2ca8e8c05c71c49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GenAI Text Generation Using Llama3 Model\n",
    "\n",
    "In this notebook, I used few-shot training method in order to train [Llama3](https://disant.medium.com/introducing-the-llama3-package-seamlessly-interact-with-metas-llama-3-model-locally-1428d2f12544) model to output results of the desired structure. I used the dataset from hugging face [DND Characters Backstories](https://huggingface.co/datasets/MohamedRashad/dnd_characters_backstories/viewer) to give examples to the model."
   ],
   "metadata": {
    "id": "VvZodkbhARHI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Few-shot training](https://medium.com/@garysvenson09/how-to-implement-few-shot-learning-with-llama3-in-langchain-6b9cdf81a60d) is a machine learning technique where a model is trained or fine-tuned to perform tasks using only a small number of examples. This helps the model to generalize and adjust to new tasks with minimal data but still use prior knowledge at the same time."
   ],
   "metadata": {
    "id": "pllmGGcKjDzJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Install the following dependencies:"
   ],
   "metadata": {
    "id": "m4KDJW07Xa-I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install torch datasets"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8CMJU_L4ZlHB",
    "outputId": "9f6ce732-764b-40d0-f939-a85ebc7584d2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m480.6/480.6 kB\u001B[0m \u001B[31m8.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m13.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m179.3/179.3 kB\u001B[0m \u001B[31m20.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m13.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.8/194.8 kB\u001B[0m \u001B[31m21.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install langchain"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVSMTRAgxQ4E",
    "outputId": "d537f611-ad0e-45a5-a81d-8ee2c1469a86"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install llama3_package"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIWfX7iOqUC-",
    "outputId": "830cf9f1-933f-4200-c46d-23fe103aae5e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting llama3_package\n",
      "  Downloading llama3_package-0.3.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from llama3_package) (0.3.14)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.11/dist-packages (from llama3_package) (6.5.5)\n",
      "Collecting ollama (from llama3_package)\n",
      "  Downloading ollama-0.4.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (0.2.10)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (2.10.5)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain->llama3_package) (9.0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (3.1.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (6.3.3)\n",
      "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (24.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (23.1.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (5.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (5.7.2)\n",
      "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (6.1.12)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (5.10.4)\n",
      "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (7.16.5)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (1.6.0)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (5.5.6)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (0.21.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook->llama3_package) (1.1.0)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from ollama->llama3_package)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama3_package) (1.18.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->llama3_package) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->llama3_package) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->llama3_package) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->llama3_package) (3.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.28.0,>=0.27.0->ollama->llama3_package) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama->llama3_package) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8,>=5.3.4->notebook->llama3_package) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.1->notebook->llama3_package) (4.3.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain->llama3_package) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain->llama3_package) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain->llama3_package) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain->llama3_package) (3.10.14)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain->llama3_package) (1.0.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook->llama3_package) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->llama3_package) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (3.0.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (3.1.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (1.5.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook->llama3_package) (2.18.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->llama3_package) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook->llama3_package) (4.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->llama3_package) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain->llama3_package) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain->llama3_package) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain->llama3_package) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->llama3_package) (3.1.1)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->notebook->llama3_package) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook->llama3_package) (21.2.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->notebook->llama3_package) (7.34.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook->llama3_package) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook->llama3_package) (1.4.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (75.1.0)\n",
      "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->notebook->llama3_package)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (3.0.48)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel->notebook->llama3_package) (4.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain->llama3_package) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->llama3_package) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->llama3_package) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook->llama3_package) (0.22.3)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->llama3_package) (1.24.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client<8,>=5.3.4->notebook->llama3_package) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->llama3_package) (1.17.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook->llama3_package) (2.6)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->llama3_package) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->notebook->llama3_package) (0.8.4)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook->llama3_package) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook->llama3_package) (0.2.13)\n",
      "Downloading llama3_package-0.3.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading ollama-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.4/76.4 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m21.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: jedi, httpx, ollama, llama3_package\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.28.1\n",
      "    Uninstalling httpx-0.28.1:\n",
      "      Successfully uninstalled httpx-0.28.1\n",
      "Successfully installed httpx-0.27.2 jedi-0.19.2 llama3_package-0.3.0 ollama-0.4.6\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from llama3 import Llama3Model"
   ],
   "metadata": {
    "id": "vfn2lHkfxVZV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ],
   "metadata": {
    "id": "evKgcDm1tGHW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate"
   ],
   "metadata": {
    "id": "96iYh3UUsogy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset"
   ],
   "metadata": {
    "id": "uHFzjCaafh5O"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import re"
   ],
   "metadata": {
    "id": "mT1eVU3JMVRA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Dataset"
   ],
   "metadata": {
    "id": "Nou8avDI3DMJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we need to load a dataset using the load_dataset function from the Hugging Face datasets library. The dataset \"dnd_characters_backstories\" is hosted on the Hugging Face Dataset Hub and contains backstories for Dungeons & Dragons (DnD) characters."
   ],
   "metadata": {
    "id": "Z_C1tEtVcUeE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"MohamedRashad/dnd_characters_backstories\")"
   ],
   "metadata": {
    "id": "_O_J3xM4E95c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "referenced_widgets": [
      "1bcfd1e8e3f74c3986a8835aa3e60272",
      "ac197af39d454bdab5a95cde348d7779",
      "736b1ad636c04ef5a81f9c847d4e07d0",
      "395e978a53ca4a889114e354bb381cee",
      "a30e9ec94fe944e2ba372056fd82c1d3",
      "752d04cc19c340e7bb12a089dcfb849c",
      "a5ff8ec368d24ec2baf63382ee60c5e7",
      "4ea1968fdea945299cfb6f7b5580b9e8",
      "610cf0065176473bbf5246a42103d0d6",
      "084704771f724cbabbc603bfb611ab23",
      "5b3627a955be4eafb85f6071cf1d9d17",
      "ab5dd08012484710a9ac2da6fb377268",
      "6f3bbb58549e4cbba225e256760c2632",
      "bad60489dfb144858d78bf4d54e83ba5",
      "9e78e4699b0240bdb5d05532215fe23d",
      "561fdfe427e2447ab3cfbd3c3fa85bcb",
      "0ca58cc8ff04474299fd139f85e38e45",
      "cf04f6aecf474c6387283322a6136d31",
      "c95494b0d0ed42f4b009b9a5778fe9a3",
      "1efa899219214297911274a303cd7389",
      "4c0bd7cfb3b44d288398a8f73f6a19e3",
      "7903b5394108418e8f8c66821073ad80",
      "5871cdfae919416da2837b2c746efcdd",
      "51a511d66ff6429fbdd4f27622358f13",
      "c3bcd2901f3a4699a4e8f1003bec25e8",
      "0f2f0cc6c9b54e81b8b7985edb6342fd",
      "6cac8841688a4a8fa9e0f5a7795c03ce",
      "6232b9fcbb22494ab60df30ef75a81d8",
      "9ed4bbc6435f458d8a53d375b69d8063",
      "696b177d73314e45bfbe90819c9de6cb",
      "24b24dbf87db4d8db04b6ce134563478",
      "ddd08cc88c474ac79a9a8f2d066f6544",
      "cfe9983cd9b84138b2ca8e8c05c71c49"
     ]
    },
    "outputId": "17e995be-1023-4e68-b7a6-58df87b307cf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/262 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bcfd1e8e3f74c3986a8835aa3e60272"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "(…)-00000-of-00001-f131735b1a05d489.parquet:   0%|          | 0.00/2.07M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab5dd08012484710a9ac2da6fb377268"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/2322 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5871cdfae919416da2837b2c746efcdd"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create a Prompt Template for the few-shot examples"
   ],
   "metadata": {
    "id": "2mt0q9IgWogQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Next, create a [PromptTemplate object](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html) using the from_template method. It defines a reusable template for few-shot examples by specifying a format where a question and its corresponding answer are included. Thus, every example which will be taken from the dataset will adhere this format for future model training.",
   "metadata": {
    "id": "I3kaGO8RitAI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Question: {question}\\n{answer}\")"
   ],
   "metadata": {
    "id": "P7Fl5ckBWAQg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create an example set from the dataset"
   ],
   "metadata": {
    "id": "AQVugpIiXRyu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Every entry from the dataset should be converted into a dictionary representing an example input to the formatter prompt we defined above."
   ],
   "metadata": {
    "id": "_4eUnrHzk9CT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thus, we first of all need to define a function to normalize every entry from the dataset because they might contain unnecessary characters."
   ],
   "metadata": {
    "id": "rkyXjslLlKkY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def normalize_text(text):\n",
    "    text = re.sub(r\"[ÓÒ]\", '\"', text)\n",
    "    text = re.sub(r\"Õ\", \"'\", text)\n",
    "    text = re.sub(r\"\\r\\r\", \"\", text)\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    text = re.sub(r\"\\. \", \".\\n\", text)\n",
    "\n",
    "    return text"
   ],
   "metadata": {
    "id": "VeWK6ukQXXCE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The next step involves extracting a few examples from the dataset, applying the normalization to them and format them as a dictionary with question and an answer keys.",
   "metadata": {
    "id": "VeKujdGClgSi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_few_shot_examples(dataset, start, end):\n",
    "    \"\"\"\n",
    "    Extracts few-shot examples from the dataset and formats them for the prompt.\n",
    "\n",
    "    Args:\n",
    "        dataset: The dataset containing character information and backstories.\n",
    "        start: The index of the first example to extract.\n",
    "        end: The index of the example after the last one to extract.\n",
    "\n",
    "    Returns:\n",
    "        A formatted string with the few-shot examples.\n",
    "    \"\"\"\n",
    "\n",
    "    examples = []\n",
    "\n",
    "    # Extract entries from the dataset[start:end]\n",
    "    for i in range(start, end):\n",
    "        entry = dataset[i]\n",
    "        example_question = entry['text']\n",
    "        example_question = re.sub(r\"Backstory\", \"a backstory\", example_question)\n",
    "        example_question = example_question[:29] + ' the' + example_question[29:]\n",
    "        example_answer = 'Backstory: ' + normalize_text(entry['target'])\n",
    "        examples.append({'question': example_question, 'answer': example_answer})\n",
    "\n",
    "    return examples\n"
   ],
   "metadata": {
    "id": "1AlPHkTYXiYv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "examples = extract_few_shot_examples(dataset['train'], 2, 8)"
   ],
   "metadata": {
    "id": "QhAUILbbXwML"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how the resulted dictionaly of examples look like:"
   ],
   "metadata": {
    "id": "B5TqmCDqlzqh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "examples"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VCZDzelgpLVm",
    "outputId": "403ebd6e-c764-47a5-b11c-c0782d50fb06"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'question': 'Generate a backstory based on the following information\\nCharacter Name: Surkiikri\\nCharacter Race: Aarakocra\\nCharacter Class: Monk\\n\\nOutput:\\n',\n",
       "  'answer': 'Backstory: Surkiikri was firstborn of the ruling family of the Mistcliffs Aarakocran colony in Chult.\\nTradition, though not law, dictates that the noble title pass to the firstborn, but Surk was passed over for his younger sister, Krilahk, a far more charismatic leader.\\nSurk initially turned to the monastery to hone his martial skills, but there he also found belonging in the simply life away from the headaches of responsibility.When word came to the monastery of new rumors of a piece of the Rod of Seven Parts, Surk felt a deeply rooted sense of responsibility stir for the people he was born, if not chosen, to lead.\\nHe left his new home in search of this artifact with the blessing of his order going with him.\\nSurk lives a highly conflicted inner life.\\nHe is content, happy even, with his life as a monk, though he still feels keenly the sting of not being good enough in the eyes of the Elder Council.\\nHowever, deeper still, lies the truth that he never wanted to be the tribal leader.\\nHe remembers the ascension of his sister to the throne with relief mingled with guilt.\\nThis conflict of desires churns underneath the generous and altruistic attitude Surk presents to the world.'},\n",
       " {'question': 'Generate a backstory based on the following information\\nCharacter Name: Azriel\\nCharacter Race: Aasamar\\nCharacter Class: Paladin\\n\\nOutput:\\n',\n",
       "  'answer': 'Backstory: He was raised the isles in a family of nobles who had close ties to the gods and there angelic guardians.\\nThen one day an army of bone devils slaughtered all the angels and anyone related or associated with them.\\nAzriel escapes the the isles to try and put his life back together until he is taken by slavers and returns to the isles once more to tyrants and monstrosities.'},\n",
       " {'question': 'Generate a backstory based on the following information\\nCharacter Name: Azophyr\\nCharacter Race: Aasimar\\nCharacter Class: Paladin\\n\\nOutput:\\n',\n",
       "  'answer': \"Backstory: Hi...\\nI'm Azophyr.\\nI'm a fallen aasimar devotion Paladin.\\nAfter an encounter with the forces of darkness, I was cast out of the heavens.\\nAnyway, Azophyr wears a visor on his helmet over his helmet for discretion.\\nIf he shows his face too often, he's gets recognized from ancient works of art and paintings in tombs.\\nSyndra, however, has seen my face and knows me enough to recognize me.\"},\n",
       " {'question': 'Generate a backstory based on the following information\\nCharacter Name: Mayanna Blackthorn\\nCharacter Race: Aasimar\\nCharacter Class: Paladin\\n\\nOutput:\\n',\n",
       "  'answer': 'Backstory: Was found on the steps of a temple to Heironeous as a young child and raised by one of the paladins.\\n Her unusual skin coloring (from being an aasimar) matched some of the descriptions of Heironeous, so the priests and paladins at the temple considered her to be blessed.\\nShe became a paladin herself and after successfully battling against forces of the evil god Hextor, she was assigned on a new mission to serve as a diplomat to a newly discovered land across the sea.'},\n",
       " {'question': 'Generate a backstory based on the following information\\nCharacter Name: Ambriel Falafel\\nCharacter Race: Aasimar\\nCharacter Class: Paladin\\n\\nOutput:\\n',\n",
       "  'answer': \"Backstory: Ambriel, the haunted one, is on a quest to vanquish evil.\\nOnce an upstanding paladin, she made the mistake of reading an Eldrich tome.\\nDespite destroying the tome, its words still echo in her mind, and she has slowly been losing her grip on her sanity and her alignment.\\nNow, she clings to her mission of taking down the greatest evil, hoping for redemption, although she no longer believes she deserves it.\\nAmbriel has fallen, and the only thing that keeps her going is knowing she's taking evil down with her.\\nAlso, she doesn't read anymore.\\nBooks are as untrustworthy as people.\"},\n",
       " {'question': 'Generate a backstory based on the following information\\nCharacter Name: Aldea\\nCharacter Race: Aasimar\\nCharacter Class: Cleric (tempest)\\n\\nOutput:\\n',\n",
       "  'answer': 'Backstory: Aldea was born in a kingdom where magic was everywhere, wizards ruled, and lacking it herself, she and her family were lower-class.\\nAt some point a wealthy nobleman recognized her noble blood and decided he wanted her as a mistress.\\nShe rejected him, and he had her family tried and executed for treason, magic disintegrating them on the spot.\\nBut he left her alive, still obsessed.\\nTerrified, Aldea begged for any god that would listen to help her, and one did: Valkyr, the god of Storms and Sailors.\\nHis power helped her to escape the city and later her country, and now she does her best to forget the past and serve her savior.'}]"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's test the formatting prompt with one of the examples:"
   ],
   "metadata": {
    "id": "mE5-5UbmhVJr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(example_prompt.invoke(examples[0]).to_string())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGzfICfEhTaV",
    "outputId": "3c9b2d23-215b-41f6-d904-59534c5243a3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Surkiikri\n",
      "Character Race: Aarakocra\n",
      "Character Class: Monk\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Surkiikri was firstborn of the ruling family of the Mistcliffs Aarakocran colony in Chult.\n",
      "Tradition, though not law, dictates that the noble title pass to the firstborn, but Surk was passed over for his younger sister, Krilahk, a far more charismatic leader.\n",
      "Surk initially turned to the monastery to hone his martial skills, but there he also found belonging in the simply life away from the headaches of responsibility.When word came to the monastery of new rumors of a piece of the Rod of Seven Parts, Surk felt a deeply rooted sense of responsibility stir for the people he was born, if not chosen, to lead.\n",
      "He left his new home in search of this artifact with the blessing of his order going with him.\n",
      "Surk lives a highly conflicted inner life.\n",
      "He is content, happy even, with his life as a monk, though he still feels keenly the sting of not being good enough in the eyes of the Elder Council.\n",
      "However, deeper still, lies the truth that he never wanted to be the tribal leader.\n",
      "He remembers the ascension of his sister to the throne with relief mingled with guilt.\n",
      "This conflict of desires churns underneath the generous and altruistic attitude Surk presents to the world.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pass the Examples and Template to FewShotPromptTemplate"
   ],
   "metadata": {
    "id": "GSQu6yN6hlwG"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Finally, [a FewShotPromptTemplate object](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html) needs to be created. This object takes a set of few-shot examples and formats them according to the formatter (example_prompt) which was sent as an argument as well. Additionally, the object uses a prefix at the beginning of the prompt (system_prompt), providing instructions to the model and a suffix which is a string to be continued by the modelbased on the format in question.",
   "metadata": {
    "id": "1yJl53H2mR8b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "system_prompt = '''You are a helpful assistant.\n",
    "Here are some example questions and how you should answer them.\n",
    "Please, follow the exact format outlined here and answer the last question in the same format.\n",
    "Make sure that you do not ask for future help at the end of the response and\n",
    "do not say that you are happy to assist at the beginning of it.\n",
    "Also make sure that you output every sentence on the new line.\n",
    "'''"
   ],
   "metadata": {
    "id": "51CzXazylZWt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=system_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"],\n",
    ")"
   ],
   "metadata": {
    "id": "4WPNbjIDhO83"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_prompt = '''Generate a backstory based on the following information:\n",
    "Character Name: Kropus\n",
    "Character Race: Tiefling\n",
    "Character Class: Mage'''"
   ],
   "metadata": {
    "id": "j0UAr4SxiOHg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see these formatted examples which will be later provided to the model to guide it to a better response."
   ],
   "metadata": {
    "id": "PDVIG1J5n4SY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\n",
    "    prompt.invoke({\"input\": user_prompt}).to_string()\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a6Z2aLyigvs9",
    "outputId": "ffda3ad3-cb87-49a4-f7b7-8eb30d034f20"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "You are a helpful assistant. \n",
      "Here are some example questions and how you should answer them. \n",
      "Please, follow the exact format outlined here and answer the last question in the same format.\n",
      "Make sure that you do not ask for future help at the end of the response and\n",
      "do not say that you are happy to assist at the beginning of it.\n",
      "Also make sure that you output every sentence on the new line.\n",
      "\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Surkiikri\n",
      "Character Race: Aarakocra\n",
      "Character Class: Monk\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Surkiikri was firstborn of the ruling family of the Mistcliffs Aarakocran colony in Chult.\n",
      "Tradition, though not law, dictates that the noble title pass to the firstborn, but Surk was passed over for his younger sister, Krilahk, a far more charismatic leader.\n",
      "Surk initially turned to the monastery to hone his martial skills, but there he also found belonging in the simply life away from the headaches of responsibility.When word came to the monastery of new rumors of a piece of the Rod of Seven Parts, Surk felt a deeply rooted sense of responsibility stir for the people he was born, if not chosen, to lead.\n",
      "He left his new home in search of this artifact with the blessing of his order going with him.\n",
      "Surk lives a highly conflicted inner life.\n",
      "He is content, happy even, with his life as a monk, though he still feels keenly the sting of not being good enough in the eyes of the Elder Council.\n",
      "However, deeper still, lies the truth that he never wanted to be the tribal leader.\n",
      "He remembers the ascension of his sister to the throne with relief mingled with guilt.\n",
      "This conflict of desires churns underneath the generous and altruistic attitude Surk presents to the world.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azriel\n",
      "Character Race: Aasamar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: He was raised the isles in a family of nobles who had close ties to the gods and there angelic guardians.\n",
      "Then one day an army of bone devils slaughtered all the angels and anyone related or associated with them.\n",
      "Azriel escapes the the isles to try and put his life back together until he is taken by slavers and returns to the isles once more to tyrants and monstrosities.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azophyr\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Hi...\n",
      "I'm Azophyr.\n",
      "I'm a fallen aasimar devotion Paladin.\n",
      "After an encounter with the forces of darkness, I was cast out of the heavens.\n",
      "Anyway, Azophyr wears a visor on his helmet over his helmet for discretion.\n",
      "If he shows his face too often, he's gets recognized from ancient works of art and paintings in tombs.\n",
      "Syndra, however, has seen my face and knows me enough to recognize me.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Mayanna Blackthorn\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Was found on the steps of a temple to Heironeous as a young child and raised by one of the paladins.\n",
      " Her unusual skin coloring (from being an aasimar) matched some of the descriptions of Heironeous, so the priests and paladins at the temple considered her to be blessed.\n",
      "She became a paladin herself and after successfully battling against forces of the evil god Hextor, she was assigned on a new mission to serve as a diplomat to a newly discovered land across the sea.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Ambriel Falafel\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Ambriel, the haunted one, is on a quest to vanquish evil.\n",
      "Once an upstanding paladin, she made the mistake of reading an Eldrich tome.\n",
      "Despite destroying the tome, its words still echo in her mind, and she has slowly been losing her grip on her sanity and her alignment.\n",
      "Now, she clings to her mission of taking down the greatest evil, hoping for redemption, although she no longer believes she deserves it.\n",
      "Ambriel has fallen, and the only thing that keeps her going is knowing she's taking evil down with her.\n",
      "Also, she doesn't read anymore.\n",
      "Books are as untrustworthy as people.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Aldea\n",
      "Character Race: Aasimar\n",
      "Character Class: Cleric (tempest)\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Aldea was born in a kingdom where magic was everywhere, wizards ruled, and lacking it herself, she and her family were lower-class.\n",
      "At some point a wealthy nobleman recognized her noble blood and decided he wanted her as a mistress.\n",
      "She rejected him, and he had her family tried and executed for treason, magic disintegrating them on the spot.\n",
      "But he left her alive, still obsessed.\n",
      "Terrified, Aldea begged for any god that would listen to help her, and one did: Valkyr, the god of Storms and Sailors.\n",
      "His power helped her to escape the city and later her country, and now she does her best to forget the past and serve her savior.\n",
      "\n",
      "Question: Generate the backstory based on the following information:\n",
      "Character Name: Kropus\n",
      "Character Race: Tiefling \n",
      "Character Class: Mage\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load the Model"
   ],
   "metadata": {
    "id": "h_lkiePejE09"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Llama3Model()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2k01OjHWjEZz",
    "outputId": "2dc8189a-3c42-4f03-f7ac-b6b0c4f5ae6b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:llama3:Ollama not found. Installing Ollama on Linux...\n",
      "INFO:llama3:Ollama installed successfully.\n",
      "INFO:llama3:Starting Ollama server in the background...\n",
      "INFO:llama3:Ollama server started successfully.\n",
      "WARNING:llama3:Attempt 1/5: Ollama server is not running yet. Retrying in 5 seconds...\n",
      "INFO:llama3:Ollama server is running.\n",
      "INFO:llama3:Pulling model llama3...\n",
      "INFO:llama3:Model llama3 pulled successfully.\n",
      "INFO:llama3:Starting Ollama with model llama3...\n",
      "INFO:llama3:Ollama started with model llama3.\n",
      "INFO:llama3:Initialized Llama3 model with model name: llama3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's generate a response based on a user-provided prompt:"
   ],
   "metadata": {
    "id": "yHFzPg9yoWTt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "response = model.prompt(prompt.invoke({\"input\": user_prompt}).to_string())\n",
    "print(\"Prompt Response:\", response)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA9AfwxAgvgj",
    "outputId": "6b09dace-1d1f-4ee3-ef7e-1bbbef2a48ea"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:llama3:Sending prompt: You are a helpful assistant. \n",
      "Here are some example questions and how you should answer them. \n",
      "Please, follow the exact format outlined here and answer the last question in the same format.\n",
      "Make sure that you do not ask for future help at the end of the response and\n",
      "do not say that you are happy to assist at the beginning of it.\n",
      "Also make sure that you output every sentence on the new line.\n",
      "\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Surkiikri\n",
      "Character Race: Aarakocra\n",
      "Character Class: Monk\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Surkiikri was firstborn of the ruling family of the Mistcliffs Aarakocran colony in Chult.\n",
      "Tradition, though not law, dictates that the noble title pass to the firstborn, but Surk was passed over for his younger sister, Krilahk, a far more charismatic leader.\n",
      "Surk initially turned to the monastery to hone his martial skills, but there he also found belonging in the simply life away from the headaches of responsibility.When word came to the monastery of new rumors of a piece of the Rod of Seven Parts, Surk felt a deeply rooted sense of responsibility stir for the people he was born, if not chosen, to lead.\n",
      "He left his new home in search of this artifact with the blessing of his order going with him.\n",
      "Surk lives a highly conflicted inner life.\n",
      "He is content, happy even, with his life as a monk, though he still feels keenly the sting of not being good enough in the eyes of the Elder Council.\n",
      "However, deeper still, lies the truth that he never wanted to be the tribal leader.\n",
      "He remembers the ascension of his sister to the throne with relief mingled with guilt.\n",
      "This conflict of desires churns underneath the generous and altruistic attitude Surk presents to the world.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azriel\n",
      "Character Race: Aasamar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: He was raised the isles in a family of nobles who had close ties to the gods and there angelic guardians.\n",
      "Then one day an army of bone devils slaughtered all the angels and anyone related or associated with them.\n",
      "Azriel escapes the the isles to try and put his life back together until he is taken by slavers and returns to the isles once more to tyrants and monstrosities.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azophyr\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Hi...\n",
      "I'm Azophyr.\n",
      "I'm a fallen aasimar devotion Paladin.\n",
      "After an encounter with the forces of darkness, I was cast out of the heavens.\n",
      "Anyway, Azophyr wears a visor on his helmet over his helmet for discretion.\n",
      "If he shows his face too often, he's gets recognized from ancient works of art and paintings in tombs.\n",
      "Syndra, however, has seen my face and knows me enough to recognize me.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Mayanna Blackthorn\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Was found on the steps of a temple to Heironeous as a young child and raised by one of the paladins.\n",
      " Her unusual skin coloring (from being an aasimar) matched some of the descriptions of Heironeous, so the priests and paladins at the temple considered her to be blessed.\n",
      "She became a paladin herself and after successfully battling against forces of the evil god Hextor, she was assigned on a new mission to serve as a diplomat to a newly discovered land across the sea.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Ambriel Falafel\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Ambriel, the haunted one, is on a quest to vanquish evil.\n",
      "Once an upstanding paladin, she made the mistake of reading an Eldrich tome.\n",
      "Despite destroying the tome, its words still echo in her mind, and she has slowly been losing her grip on her sanity and her alignment.\n",
      "Now, she clings to her mission of taking down the greatest evil, hoping for redemption, although she no longer believes she deserves it.\n",
      "Ambriel has fallen, and the only thing that keeps her going is knowing she's taking evil down with her.\n",
      "Also, she doesn't read anymore.\n",
      "Books are as untrustworthy as people.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Aldea\n",
      "Character Race: Aasimar\n",
      "Character Class: Cleric (tempest)\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Aldea was born in a kingdom where magic was everywhere, wizards ruled, and lacking it herself, she and her family were lower-class.\n",
      "At some point a wealthy nobleman recognized her noble blood and decided he wanted her as a mistress.\n",
      "She rejected him, and he had her family tried and executed for treason, magic disintegrating them on the spot.\n",
      "But he left her alive, still obsessed.\n",
      "Terrified, Aldea begged for any god that would listen to help her, and one did: Valkyr, the god of Storms and Sailors.\n",
      "His power helped her to escape the city and later her country, and now she does her best to forget the past and serve her savior.\n",
      "\n",
      "Question: Generate the backstory based on the following information:\n",
      "Character Name: Kropus\n",
      "Character Race: Tiefling \n",
      "Character Class: Mage\n",
      "INFO:llama3:Prompt successful: You are a helpful assistant. \n",
      "Here are some example questions and how you should answer them. \n",
      "Please, follow the exact format outlined here and answer the last question in the same format.\n",
      "Make sure that you do not ask for future help at the end of the response and\n",
      "do not say that you are happy to assist at the beginning of it.\n",
      "Also make sure that you output every sentence on the new line.\n",
      "\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Surkiikri\n",
      "Character Race: Aarakocra\n",
      "Character Class: Monk\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Surkiikri was firstborn of the ruling family of the Mistcliffs Aarakocran colony in Chult.\n",
      "Tradition, though not law, dictates that the noble title pass to the firstborn, but Surk was passed over for his younger sister, Krilahk, a far more charismatic leader.\n",
      "Surk initially turned to the monastery to hone his martial skills, but there he also found belonging in the simply life away from the headaches of responsibility.When word came to the monastery of new rumors of a piece of the Rod of Seven Parts, Surk felt a deeply rooted sense of responsibility stir for the people he was born, if not chosen, to lead.\n",
      "He left his new home in search of this artifact with the blessing of his order going with him.\n",
      "Surk lives a highly conflicted inner life.\n",
      "He is content, happy even, with his life as a monk, though he still feels keenly the sting of not being good enough in the eyes of the Elder Council.\n",
      "However, deeper still, lies the truth that he never wanted to be the tribal leader.\n",
      "He remembers the ascension of his sister to the throne with relief mingled with guilt.\n",
      "This conflict of desires churns underneath the generous and altruistic attitude Surk presents to the world.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azriel\n",
      "Character Race: Aasamar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: He was raised the isles in a family of nobles who had close ties to the gods and there angelic guardians.\n",
      "Then one day an army of bone devils slaughtered all the angels and anyone related or associated with them.\n",
      "Azriel escapes the the isles to try and put his life back together until he is taken by slavers and returns to the isles once more to tyrants and monstrosities.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Azophyr\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Hi...\n",
      "I'm Azophyr.\n",
      "I'm a fallen aasimar devotion Paladin.\n",
      "After an encounter with the forces of darkness, I was cast out of the heavens.\n",
      "Anyway, Azophyr wears a visor on his helmet over his helmet for discretion.\n",
      "If he shows his face too often, he's gets recognized from ancient works of art and paintings in tombs.\n",
      "Syndra, however, has seen my face and knows me enough to recognize me.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Mayanna Blackthorn\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Was found on the steps of a temple to Heironeous as a young child and raised by one of the paladins.\n",
      " Her unusual skin coloring (from being an aasimar) matched some of the descriptions of Heironeous, so the priests and paladins at the temple considered her to be blessed.\n",
      "She became a paladin herself and after successfully battling against forces of the evil god Hextor, she was assigned on a new mission to serve as a diplomat to a newly discovered land across the sea.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Ambriel Falafel\n",
      "Character Race: Aasimar\n",
      "Character Class: Paladin\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Ambriel, the haunted one, is on a quest to vanquish evil.\n",
      "Once an upstanding paladin, she made the mistake of reading an Eldrich tome.\n",
      "Despite destroying the tome, its words still echo in her mind, and she has slowly been losing her grip on her sanity and her alignment.\n",
      "Now, she clings to her mission of taking down the greatest evil, hoping for redemption, although she no longer believes she deserves it.\n",
      "Ambriel has fallen, and the only thing that keeps her going is knowing she's taking evil down with her.\n",
      "Also, she doesn't read anymore.\n",
      "Books are as untrustworthy as people.\n",
      "\n",
      "Question: Generate a backstory based on the following information\n",
      "Character Name: Aldea\n",
      "Character Race: Aasimar\n",
      "Character Class: Cleric (tempest)\n",
      "\n",
      "Output:\n",
      "\n",
      "Backstory: Aldea was born in a kingdom where magic was everywhere, wizards ruled, and lacking it herself, she and her family were lower-class.\n",
      "At some point a wealthy nobleman recognized her noble blood and decided he wanted her as a mistress.\n",
      "She rejected him, and he had her family tried and executed for treason, magic disintegrating them on the spot.\n",
      "But he left her alive, still obsessed.\n",
      "Terrified, Aldea begged for any god that would listen to help her, and one did: Valkyr, the god of Storms and Sailors.\n",
      "His power helped her to escape the city and later her country, and now she does her best to forget the past and serve her savior.\n",
      "\n",
      "Question: Generate the backstory based on the following information:\n",
      "Character Name: Kropus\n",
      "Character Race: Tiefling \n",
      "Character Class: Mage\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prompt Response: Here is the generated backstory:\n",
      "\n",
      "Backstory: Kropus was born into a family of powerful sorcerers who had made a pact with a demon to increase their magical abilities. As a result, Kropus inherited some of this dark energy and became a skilled mage.\n",
      "\n",
      "Growing up among his family's collection of ancient tomes and forbidden knowledge, Kropus became fascinated with the mysteries of the arcane arts. He spent countless hours studying and experimenting, mastering spells that would make even the most seasoned wizards jealous.\n",
      "\n",
      "\n",
      "How is this?\n",
      "\n",
      "\n"
     ]
    }
   ]
  }
 ]
}
